\chapter{Some Special Functions}
Power series, $e^{x}, \log{x},\sin{x},\cos{x}$, Fourier series (we're omitting Gamma function)

\section{Power Series}
Recall $\sum_{n=0}^{\infty}{c_n{x^{n}}}$ has a radius of convergence $R=\frac{1}{\limsup_{n\to \infty}{\sqrt[n]{\left|c_{n}\right| }}}$ such that the series absolutely converges for $\left|x\right| < R$, diverges for $\left|x\right| >R$ and anything possible for $\left|x\right| =R$.

\begin{remark}
	To determine $R$, we often use the ratio test instead:
	\[
		\left|\frac{c_{n+1}x^{n+1}}{c_nx^{n}}\right| =\left|x\right| \cdot \left|\frac{c_{n+1}}{c_n}\right|\underbrace{\to}_{\text{ if limit exists } } \left|x\right| \cdot L\implies \text{ absolute convergence if } \left|x\right| <\frac{1}{L}, \text{ diverges if }  \left|x\right| >\frac{1}{L}
		,\] where $R=\frac{1}{L}=\frac{1}{\lim_{n\to \infty}{\left|\frac{c_{n+1}}{c_n}\right| }}$.\\
	In general, by Theorem~3.37, we also have \[
		\frac{1}{\liminf_{n\to \infty}{\left|\sqrt[n]{c_n}\right|}}\le R\le \frac{1}{\liminf_{n\to \infty}{\frac{c_{n+1}}{c_n}}}
		.\]
\end{remark}

\begin{theorem}[1]
	Suppose $\sum_{n=0}^{\infty}{c_n x^{n}}$ has a radius of convergence $R>0$ and define $f(x)=\sum_{n=0}^{\infty}{c_n x^{n}}$ for $\left|x\right| < R$. Such a function $f(x)$ is called an \textit{analytic function} .\\
	If $R<\infty$, then the series converges uniformly on $[-R+\epsilon,R-\epsilon]$ for all $\epsilon>0$.\\
	If $R=\infty$, then the series converges uniformly on $[-M,M]$ for all $M < \infty$.
	The function $f$ is continuous and differentiable on $(-R,R)$ with $f'(x)=\sum_{n}{c_n n x^{n-1}}$
	\begin{note}
		Uniform convergence may not hold on $(-R,R)$. C.f. A7-Q3.
	\end{note}
	\begin{proof}
		\hfill
		\begin{description}
			\item[Uniform convergence:]
			      For $\left|x\right| \le R-\epsilon$, $\left|c_n x^{n}\right|\le \left|c_n\right| (R-\epsilon)^{n}$.\\
			      Since $\sum_{n=0}^{\infty}{\left|c_n\right|(R-\epsilon)^{n}}<\infty$ by absolute convergence on $(-R,R)$. Hence, by Weierstrass M-test, $\sum_{n=0}^{\infty}{c_n x^{n}}$ converges uniformly on $[-R+\epsilon,R-\epsilon]$.\\
			\item[Derivative:]
			      The radius of convergence of $\sum_{n=1}^{\infty}{nc_n x^{n-1}}$ is
			      \begin{flalign*}
				      \frac{1}{\limsup_{n\to \infty}{\sqrt[n]{n \left|c_n\right| }}} & =\frac{1}{\limsup_{n\to \infty}{\sqrt[n]{n}\sqrt[n]{\left|c_n\right|}}}                                                   \\
				                                                                     & =\text{ radius of convergence of } \sum_{n=0}^{\infty}{c_n x^{n}} \text{  ($\because \lim_{n\to \infty}{\sqrt[n]{n}}=1$)}
				      .\end{flalign*}
			      Let $S_n(x)=\sum_{m=0}^{n}{c_m x^{m}}$. Then $S'_n(x)=\sum_{m=1}^{n}{c_m m x^{m-1}}$.
			      By the first part of the proof, $S'_n(x)\to \sum_{m=1}^{\infty}{c_m m x^{m-1}}$ uniformly on $[-R+\epsilon, R-\epsilon]$. Since also $S_n(x)\to f(x)$, by Theorem~\ref{thm:7.17}, $f'$ exists on $[-R+\epsilon,R-\epsilon]$, and $f'(x)=\sum_{m=1}^{\infty}{c_m m x^{m-1}}$.\\
			      Since $\epsilon$ is arbitrary, $f'(x)=\sum_{m=1}^{\infty}{c_m m x^{m-1}}$ for all $x \in (-R,R)$. In particular, $f$ is also continuous.
		\end{description}
	\end{proof}
\end{theorem}

\begin{corollary}
	If $f(x)=\sum_{n=0}^{\infty}{c_n x^{n}}$ converges for $\left|x\right| < R$, then $f^{(k)}(x)$ exists for all $k \in \N$, and
	\begin{equation*}
		f^{(k)}(x)=\sum_{n=k}^{\infty}{c_n n(n-1)\cdots (n-k+1)x^{n-k}}
		\tag{*}
		.\end{equation*}
	Consequently, $c_k=f^{(k)}(0)$ and $f(x)=\sum_{n=0}^{\infty}{\frac{f^{(n)}(0)}{n!} x^{n}}$.
	\begin{note}
		C.f. Taylor's theorem.
	\end{note}
	\begin{proof}
		By Theorem~\ref{thm:8.1}, $f'(x)=\sum_{n=1}^{\infty}{c_n n x^{n-1}}, f''(x)=(f')'(x)=\sum_{n=2}^{\infty}{c_n n(n-1)x^{n-2}}, \ldots $.\\
		Set $x=0$ in (*) to get $f^{(k)}(0)\underbrace{=}_{\text{ only } n=k \text{ term survives } }c_k k (k-1) \cdots \cdot 1=c_k\cdot  k!$.
	\end{proof}
\end{corollary}
\begin{example}
	Let $f(x)=\begin{cases}
			e^{-\frac{1}{x^2}} & x\neq 0 \\
			0                  & x=0
		\end{cases}$.
	By Rudin's problem 8.1, $f^{(n)}(0)=0$ for all $n=0,1,2,\ldots $, so
	$f(x)\neq \sum_{n=0}^{\infty}{\frac{f^{(n)}}{n!} x^{n}}$ except for $x=0$.
	\begin{remark}[Bump Function]
		\textit{Bump functions} are infinitely differentiable functions with compact support. E.g.,
		\[
			f(x)=\begin{cases}
				e^{-\frac{1}{1-x^2}} & x \in (-1,1)         \\
				0                    & \left|x\right| \ge 1
			\end{cases}
			.\]
	\end{remark}
\end{example}

\begin{thm}[2][\namedlabel{thm:abel}{Abel's Theorem}]
	Suppose $\sum_{n=0}^{\infty}{c_n}$ converges (perhaps conditionally). Let $f(x)=\sum_{n=0}^{\infty}{c_n x^{n}}$.
	Then $f(x)$ converges for $\left|x\right| < 1$ and $\lim_{x\to 1^{-}}{f(x)}=f(1)=\sum_{n=0}^{\infty}{c_n}$.
	\begin{remark}
		Interesting case is at $R=1$, since $R>1$ implies continuity of $f$ for $\left|x\right| < R$.
	\end{remark}
	\begin{proof}
		By the root test, $\limsup_{n\to \infty}{\sqrt[n]{\left|c_n\right|}}\le 1$, so $\sum_{n=0}^{\infty}{c_n x^{n}}$ has $R\ge 1$.
		Let $S_n=\sum_{m=0}^{n}{c_m}$ and $S=\sum_{m=0}^{\infty}{c_m}=\lim_{n\to \infty}{S_n}$.\\
		Set $S_{-1}=0$. Then $c_{n}=s_{n}-s_{n-1}$ for $n\ge 0$.\\
		Let $\epsilon>0$. We need to show $\exists{\delta > 0} \text{ such that } 1-\delta<x<1 \implies \left|f(x)-S\right| < \epsilon$.\\
		Start with partial sum for $f(x)$. For $\left|x\right| < 1$,
		\begin{flalign*}
			\sum_{m=0}^{n}{c_m x^{m}}=\sum_{m=0}^{n}{(S_m-S_{m-1})x^{m}}=\sum_{m=0}^{n}{S_m x^{m}}-\sum_{m=0}^{n}{S_{m-1}x^{m}}
			.\end{flalign*}
		Let $k=m-1$ so that $m=k+1$. Then
		\begin{flalign*}
			\sum_{m=-1}^{n}{S_{m-1}x^{m}} & =x\sum_{k=0}^{n-1}{S_k x^{k}}                                                                                                                     \\
			\sum_{m=0}^{n}{c_m x^{m}}     & =(1-x)\sum_{m=0}^{n}{S_m x^{m}}+\underbrace{S_n x^{n+1}}_{\to 0 \text{ as } n\to \infty \text{ since $S_n$ is bounded and $\left|x\right| < 1$} }
			.\end{flalign*}
		Let $n\to \infty$.
		Then
		\begin{flalign*}
			f(x) & =(1-x)\sum_{n=0}^{\infty}{S_n x^{n}}+0=(1-x)S
			.\end{flalign*}
		\begin{flalign*}
			\left|f(x)-S\right| & =\left|(1-x)\sum_{n=0}^{\infty}{S_n x^{n}}-S(1-x) \cdot \frac{1}{1-x}\right|
			=	\left|(1-x)\sum_{n=0}^{\infty}{S_n x^{n}}-S(1-x)\sum_{n=0}^{\infty}{x^{n}}\right|                \\                                                                                   & =(1-x) \left|\sum_{n=0}^{\infty}{(S_n-S)x^{n}}\right|\le (1-x)\sum_{n=0}^{\infty}{\left|S_n-S\right|\cdot \left|x \right|^{n}  }
			.\end{flalign*}
		Choose $N$ s.t. $n\ge N \implies \left|S_n-S\right|<\frac{\epsilon}{2} $.
		For $x \in (0,1)$,
		\begin{flalign*}
			\left|f(x)-S\right| & \le (1-x) \sum_{n=0}^{N}{\left|S_n-S\right| x^{n}}+(1-x) \sum_{n=N+1}^{\infty}{\left|S_n-S\right|x^{n}}     \\
			                    & <(1-x) \sum_{n=0}^{N}{\left|S_n-S\right| x^{n}} +(1-x)\left( \frac{\epsilon}{2} \cdot \frac{1}{1-x}\right)=
			(1-x) \sum_{n=0}^{N}{\left|S_n-S\right| x^{n}}+\frac{\epsilon}{2}
			.\end{flalign*}
		Since $(1-x)\sum_{n=0}^{N}{\left|S_n-S\right| x^{n}}$ is a polynomial in $x$, so it is continuous and equals $0$ at $x=1$.\\
		Hence, $(1-x)\sum_{n=0}^{N}{\left|S_n-S\right| x^{n}}<\frac{\epsilon}{2}$ if $\left|x-1\right| <\delta$ for some $\delta>0$. Therefore, for $1-\delta<x<1$, $\left|f(x)-S\right|<\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon$.
	\end{proof}
	\begin{note}
		For an application of Abel's theorem, see Rudin's p. 175.\\
		For the case $\sum_{n=0}^{\infty}{c_n}=\infty$, see A7.
	\end{note}
\end{thm}

\begin{thm}[3]
	If $\sum_{i=1}^{\infty}{\sum_{j=1}^{\infty}{\left|a_{ij}\right|}}$ converges, then \[
		\sum_{i=1}^{\infty}{\sum_{j=1}^{\infty}{a_{ij}}}= \sum_{j=1}^{\infty}{\sum_{i=1}^{\infty}{a_{ij}}},\] where both sides converge.
	\begin{proof}
		Rudin has a too clever proof \ldots  A7 involves a more straightforward proof.
	\end{proof}
\end{thm}

\begin{thm}[4]
	Suppose $f(x)=\sum_{n=0}^{\infty}{c_n x^{n}}$ (Taylor series of $f$ at $x=0$, a.k.a Maclauren series) has a radius of convergence $R>0$.
	Let $\left|a\right|<R$.
	Then $f(x)=\sum_{n=0}^{\infty}{\frac{f^{(n)}(a)}{n!}(x-a)^{n}}$ for (at least) $\left|x-a\right|<R-\left|a\right|$.
	\begin{proof}
		Note \[
			f(x)=\sum_{n=0}^{\infty}{c_n \left( a+(x-a) \right)^{n}}=\sum_{n=0}^{\infty}{c_n}\sum_{m=0}^{n}{\binom{n}{m}(x-a)^{m}a^{n-m}}
			.\]
		We want to interchange the order of summation.\\
		By Theorem~\ref{thm:8.3}, interchange of summations is justified if \[
			\sum_{n=0}^{\infty}{\sum_{m=0}^{n}{\left|c_n\right|\binom{n}{m}\left|x-a\right|^{m}\left|a\right|^{n-m}}}<\infty
			.\]
		Note $\sum_{n=0}^{\infty}{\left|c_{n}\right|\left( \left|x-a\right|+\left|a\right|\right)^{n}}$ does converge as we assume $\left|x-a\right|+\left|a\right|<R$.\\
		Therefore, for $\left|x-a\right| < R-\left|a\right|$,
		\begin{flalign*}
			f(x) & =\sum_{m}^{\infty}\frac{1}{m!}(x-a)^{m}{\sum_{n=m}^{\infty}{c_n[ n\cdot (n-1)(n-2)\cdots \cdot (n-m+1)] a^{n-m}}} \\
			     & =\sum_{m}{\left(\sum_{n}{c_n \binom{n}{m}a^{n-m}}\right)(x-a)^{m}}                                                \\
			     & =\sum_{m}{\left(\sum_{n}{\frac{f^{(n)}(a)}{n!}n(n-1)\cdots (n-m+1)a^{n-m}}\right)(x-a)^{m}}                       \\
			.\end{flalign*}
	\end{proof}
	\begin{example}
		Let $f(x)=\sum_{n=0}^{\infty}{x^{n}}$ for $\left|x\right|<1 $. Then $f(x)=\frac{1}{1-x}$ for $\left|x\right|<1$.\\
		Taylor series of $\frac{1}{1-x}$ at $x=-\frac{1}{2}$:
		For $\left|x\right| < 1$, $f^{(n)}(x)=\frac{n!}{(1-x)^{n+1}}$, so $f^{(n)}(-\frac{1}{2})=\frac{n!}{(\frac{3}{2})^{n+1}}$.\\
		By Theorem~\ref{thm:8.4},
		\[
			f(x)=\sum_{n=0}^{\infty}{\frac{n!}{(\frac{3}{2})^{n+1}n!}\left(x+\frac{1}{2}\right)^{n}}=\sum_{n=0}^{\infty}{(\frac{2}{3})^{n}\left(x+\frac{1}{2}\right)^{n}}
		\]
		for $\left|x+\frac{1}{2}\right|<1-\left|-\frac{1}{2}\right| =\frac{1}{2}$.\\
		In fact, the series converges even when $\left|\frac{2}{3}\left(x+\frac{1}{2}\right)\right|<1$; i.e., $\left|x+\frac{1}{2}\right| <\frac{3}{2}$. C.f. Analytic continuation.\\
		Another way to get Taylor series at $x=-\frac{1}{2}$:\\
		For $\left|x\right|<1 $,
		\[
			f(x)=\frac{1}{1-x}=\frac{1}{\left(1+\frac{1}{2}\right)-\left(x+\frac{1}{2}\right)}=\frac{2}{3} \frac{1}{1-\frac{2}{3}\left(x+\frac{1}{2}\right)}=\frac{2}{3}\sum_{n=0}^{\infty}{\left(\frac{2}{3}\right)^{n}\left(x+\frac{1}{2}\right)^n}.
		\]
	\end{example}
\end{thm}

\begin{thm}[5][Principle of Permanence of Form]
	Suppose $\sum_{n}{a_{n}x^{n}}$ and $\sum_{n}{b_{n}x^{n}}$ have radii of convergence at least  $R$. Suppose $D \subset (-R,R)$ has a limit point in $(-R,R)$.\\
	If $\sum_{n}{a_{n}x^{n}}=\sum_{n}{b_{n}x^{n}}$ for all $x \in D$, then $a_{n}=b_{n}$ for all $n$, and hence $\sum_{n}{a_{n}x^{n}}=\sum_{n}{b_{n}x^{n}}$ for all $\left|x\right|<R$.
	\namedlabel{thm:pop}{Principle of Permanence of Form}
	\begin{proof}
		Let $c_{n}=a_{n}-b_{n}$ and $f(x)=\sum_{n=0}^{\infty}{c_n x^{n}}$.
		Then $f(x)=0$ for all $x \in D$.\\
		Let $E=\{x \in (-R,R): f(x)=0\}$. Then $D \subset E$.\\
		We want to show $E=(-R,R)$.
		Let $A=E' \cap (-R,R)$. Then $A\neq \emptyset$ because $D$ has a limit point in $(-R,R)$.\\
		Also, relative to $(-R,R)$, $A$ is closed as the set of limit points is always closed (C.f. Problem 2.6).\\
		Let $B=(-R,R)\setminus A$. Then $A\cup B=(-R,R)$, $A\cap B=\emptyset$, and $B$ is open.\\
		\begin{claim}
			$A$ is also open.
			\begin{proof}
				Let $x_{0}' \in A=E' \cap (-R,R)$.
				Then $\exists{\{ {d}_{n}\}} \text{ such that } f(x)=\sum_{n=0}^{\infty}{d_n (x-x_{0}}^{n}$.
				TODO
			\end{proof}
		\end{claim}
		Given the claim, in $(-R,R)$, $A$ and $B$ are both open and closed.
		Since $(-R,R)$ is connected (C.f. MATH-320's A5.3(c)),
		one of \begin{enumerate}
			\item $A=\emptyset,B=(-R,R)$
			\item $A=(-R,R),B=\emptyset$
		\end{enumerate}
		must hold.\\
		As $A$ is non-empty, $A=(-R,R)=E'$.\\
		Therefore, $\forall{x \in (-R,R)}: \exists{\{ {x}_{n}\} \text{ in } E} \text{ such that } x_n\to x$.
		Since $f$ is continuous on $(-R,R)$, $f(x)=\lim_{n\to \infty}{f(x_n)}=0$.\\
		Therefore, $x \in E$, so $(-R,R)\subset E$.
	\end{proof}
\end{thm}

